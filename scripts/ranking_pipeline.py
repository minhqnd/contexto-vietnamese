# -*- coding: utf-8 -*-
"""
Ranking Pipeline for Contexto Game
Adapted for GitHub Actions - Runs daily at 12:00
"""

import pickle
import numpy as np
import json
import faiss
import os
import sys
import unicodedata
import time
import subprocess
from pathlib import Path
from sentence_transformers import SentenceTransformer
from google import genai
from pydantic import BaseModel, Field
from typing import List
import glob

# Force unbuffered output for GitHub Actions
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

# =========================== Cáº¤U HÃŒNH ===========================

EMBEDDING_MODELS = {
    "dangvantuan": {"path": "dangvantuan/vietnamese-embedding", "weight": 1.2},
    "bkcare":      {"path": "nampham1106/bkcare-embedding", "weight": 1.0},
    "vovanphuc":   {"path": "VoVanPhuc/sup-SimCSE-VietNamese-phobert-base", "weight": 1.0}
}

CACHE_DIR = "model_cache"
INPUT_FOLDER = "pre_rerank"
OUTPUT_FOLDER = "output"
TOP_K_RERANK = 1000

# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c contexto trong project
CONTEXTO_DIR = Path(__file__).parent.parent / "lib" / "data" / "contexto"

# API Configuration
GOOGLE_API_KEY = os.environ.get('GOOGLE_API_KEY', '')
MODEL_NAME = "gemini-2.5-flash"

# Hint ranges cho progressive hint system (dá»±a theo logic trong contexto API)
HINT_RANGES = [
    (1001, 2000),
    (701, 1000),
    (501, 700),
    (351, 500),
    (251, 350),
    (181, 250),
    (131, 180),
    (91, 130),
    (61, 90),
    (41, 60),
    (26, 40),
    (16, 25),
    (9, 15),
    (2, 8)
]

# TÃ¬m model_cache á»Ÿ nhiá»u vá»‹ trÃ­ cÃ³ thá»ƒ
def get_cache_dir():
    possible_paths = [
        Path("model_cache"),                          # Cháº¡y tá»« root
        Path(__file__).parent / "model_cache",        # Trong scripts/
        Path(__file__).parent.parent / "model_cache", # á» thÆ° má»¥c cha
    ]
    
    for path in possible_paths:
        if path.exists():
            print(f"âœ… Sá»­ dá»¥ng model_cache táº¡i: {path}")
            return str(path)
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y, táº¡o má»›i á»Ÿ thÆ° má»¥c cha
    cache_path = Path(__file__).parent.parent / "model_cache"
    cache_path.mkdir(exist_ok=True)
    print(f"ğŸ“ Táº¡o model_cache má»›i táº¡i: {cache_path}")
    return str(cache_path)

CACHE_DIR = get_cache_dir()
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(INPUT_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# =========================== SCHEMA DEFINITIONS ===========================

class BrainstormResponse(BaseModel):
    words: List[str] = Field(description="List of brainstormed words")

class WordScore(BaseModel):
    w: str = Field(description="The candidate word")
    s: int = Field(description="Relevance score (0-100)")

class RankingResponse(BaseModel):
    items: List[WordScore] = Field(description="List of ranked words with scores")

class DailyTargetResponse(BaseModel):
    target: str = Field(description="Vietnamese target word for today's game (no underscores, just spaces)")

class HintSelection(BaseModel):
    word: str = Field(description="The selected hint word")
    rank: int = Field(description="The rank of the selected word")

class HintResponse(BaseModel):
    hints: List[HintSelection] = Field(description="List of selected hints for each range")

# =========================== UTILS ===========================

def remove_vietnamese_accents(text):
    text = text.replace("Ä‘", "d").replace("Ä", "D")
    normalized = unicodedata.normalize('NFD', text)
    return "".join([c for c in normalized if unicodedata.category(c) != 'Mn'])

def load_vocab():
    # TÃ¬m file clean_dict.pkl á»Ÿ nhiá»u vá»‹ trÃ­
    possible_paths = [
        "clean_dict.pkl",                    # Cháº¡y tá»« scripts/
        "../clean_dict.pkl",                 # Cháº¡y tá»« thÆ° má»¥c con
        Path(__file__).parent / "clean_dict.pkl",  # CÃ¹ng thÆ° má»¥c vá»›i script
    ]
    
    for path in possible_paths:
        try:
            with open(path, "rb") as f:
                vocab = pickle.load(f)
                print(f"âœ… Loaded vocab from: {path}")
                return vocab
        except FileNotFoundError:
            continue
    
    print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y clean_dict.pkl á»Ÿ báº¥t ká»³ vá»‹ trÃ­ nÃ o, dÃ¹ng vocab demo")
    return ["bÃ¡c_sÄ©", "y_tÃ¡", "bá»‡nh_viá»‡n"] * 10000

def get_existing_keywords():
    """
    Äá»c táº¥t cáº£ file .json trong thÆ° má»¥c contexto vÃ  láº¥y danh sÃ¡ch tá»« khÃ³a Ä‘Ã£ cÃ³
    """
    existing_keywords = []
    
    if not CONTEXTO_DIR.exists():
        print(f"âš ï¸  ThÆ° má»¥c {CONTEXTO_DIR} khÃ´ng tá»“n táº¡i")
        return existing_keywords
    
    # Láº¥y táº¥t cáº£ file .json (trá»« rankLoader.json vÃ  create_rank_loader.py)
    json_files = list(CONTEXTO_DIR.glob("*.json"))
    json_files = [f for f in json_files if f.name not in ["rankLoader.json"]]
    
    for json_file in json_files:
        # Láº¥y tÃªn file (vÃ­ dá»¥: bac_si.json -> bÃ¡c sÄ©)
        slug = json_file.stem  # bac_si
        # Chuyá»ƒn tá»« bac_si -> bÃ¡c sÄ© (Ä‘á»c tá»« file Ä‘á»ƒ láº¥y keyword chÃ­nh xÃ¡c)
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                keyword = data.get('keyword', '')
                if keyword:
                    existing_keywords.append(keyword)
        except:
            # Náº¿u khÃ´ng Ä‘á»c Ä‘Æ°á»£c file, dÃ¹ng slug
            keyword = slug.replace('_', ' ')
            existing_keywords.append(keyword)
    
    return existing_keywords

# =========================== LLM FUNCTIONS ===========================

def generate_daily_target():
    """
    DÃ¹ng Gemini Ä‘á»ƒ táº¡o má»™t tá»« khÃ³a má»›i cho ngÃ y hÃ´m nay
    Kiá»ƒm tra vÃ  trÃ¡nh cÃ¡c tá»« Ä‘Ã£ tá»“n táº¡i
    """
    print("ğŸ² Äang táº¡o tá»« khÃ³a má»›i cho hÃ´m nay...")
    
    # Láº¥y danh sÃ¡ch tá»« khÃ³a Ä‘Ã£ cÃ³
    existing_keywords = get_existing_keywords()
    print(f"   ğŸ“‹ ÄÃ£ cÃ³ {len(existing_keywords)} tá»« khÃ³a: {', '.join(existing_keywords[:10])}{'...' if len(existing_keywords) > 10 else ''}")
    
    client = genai.Client(api_key=GOOGLE_API_KEY)
    
    # Táº¡o danh sÃ¡ch tá»« Ä‘Ã£ cÃ³ Ä‘á»ƒ gá»­i cho Gemini
    existing_list = ', '.join(existing_keywords) if existing_keywords else 'chÆ°a cÃ³ tá»« nÃ o'
    
    prompt = f"""
Báº¡n lÃ  chuyÃªn gia thiáº¿t káº¿ game Contexto tiáº¿ng Viá»‡t.

HÃ£y Ä‘á» xuáº¥t Má»˜T tá»« khÃ³a tiáº¿ng Viá»‡t 2 Ã¢m tiáº¿t phÃ¹ há»£p cho game Contexto hÃ´m nay.

TiÃªu chÃ­:

LÃ  danh tá»«, Ä‘á»™ng tá»«, tÃ­nh tá»« hoáº·c tráº¡ng tá»« thÃ´ng dá»¥ng trong tiáº¿ng Viá»‡t.
Pháº¡m vi rá»™ng: CÃ³ thá»ƒ lÃ  Ä‘á»“ váº­t, Ä‘á»‹a Ä‘iá»ƒm, nghá» nghiá»‡p, Ä‘á»™ng váº­t, thá»±c váº­t, hÃ nh Ä‘á»™ng, tráº¡ng thÃ¡i, tÃ­nh cháº¥t, cáº£m xÃºc, khÃ¡i niá»‡m, mÃ u sáº¯c, bá»™ pháº­n cÆ¡ thá»ƒ, hoáº·c báº¥t ká»³ tá»« nÃ o cÃ³ thá»ƒ gá»£i ra nhiá»u liÃªn tÆ°á»Ÿng.
Äá»™ khÃ³ trung bÃ¬nh Ä‘áº¿n khÃ³: TrÃ¡nh nhá»¯ng tá»« quÃ¡ hiá»ƒn nhiÃªn hoáº·c quÃ¡ cá»¥ thá»ƒ. Má»¥c tiÃªu lÃ  táº¡o ra "aha moment" cho ngÆ°á»i chÆ¡i.
CÃ³ nhiá»u tá»« liÃªn quan Ä‘á»ƒ ngÆ°á»i chÆ¡i brainstorm, cáº£ trá»±c tiáº¿p vÃ  giÃ¡n tiáº¿p.
TrÃ¡nh tá»« quÃ¡ chuyÃªn ngÃ nh, tá»« cá»•, tá»« Ä‘á»‹a phÆ°Æ¡ng hiáº¿m gáº·p.
TrÃ¡nh cÃ¡c tá»« cÃ¹ng chá»§ Ä‘á» quÃ¡ rÃµ rÃ ng vá»›i cÃ¡c tá»« Ä‘Ã£ tá»“n táº¡i bÃªn dÆ°á»›i.
QUAN TRá»ŒNG: KHÃ”NG Ä‘Æ°á»£c tráº£ vá» cÃ¡c tá»« Ä‘Ã£ tá»“n táº¡i sau Ä‘Ã¢y:
{existing_list}

VÃ­ dá»¥ tá»« tá»‘t: "bÃ¡c sÄ©", "xe mÃ¡y", "trÆ°á»ng há»c", "cÃ  phÃª", "ná»—i buá»“n", "lÃ¡i xe", "mÃ u Ä‘á»", "cÃ¡i báº«y", "á»‘p la", "cÃ¡i cháº£o", "mÃ n hÃ¬nh", "cháº¡y bá»™"

CHá»ˆ TRáº¢ Vá»€ Má»˜T Tá»ª DUY NHáº¤T, khÃ´ng giáº£i thÃ­ch.
    """
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=prompt,
                config={
                    "response_mime_type": "application/json",
                    "response_json_schema": DailyTargetResponse.model_json_schema(),
                },
            )
            result = DailyTargetResponse.model_validate_json(response.text)
            target = result.target.lower().strip()
            
            # Kiá»ƒm tra náº¿u tá»« Ä‘Ã£ tá»“n táº¡i
            if target in existing_keywords:
                print(f"   âš ï¸  Tá»« '{target}' Ä‘Ã£ tá»“n táº¡i, thá»­ láº¡i...")
                continue
            
            print(f"   âœ… Tá»« khÃ³a hÃ´m nay: '{target}'")
            return target
        except Exception as e:
            print(f"   âš ï¸ Lá»—i khi táº¡o target (láº§n {attempt + 1}): {e}")
            if attempt == max_retries - 1:
                raise Exception(f"KhÃ´ng thá»ƒ táº¡o target sau {max_retries} láº§n thá»­: {e}")
    
    raise Exception("KhÃ´ng thá»ƒ táº¡o target")

def llm_brainstorm(target):
    """
    DÃ¹ng LLM Ä‘á»ƒ nghÄ© ra cÃ¡c tá»« quan trá»ng (Signature Words)
    mÃ  Embedding cÃ³ thá»ƒ Ä‘Ã£ bá» sÃ³t.
    """
    print(f"[LLM] Äang Brainstorming cho '{target}'...")
    
    client = genai.Client(api_key=GOOGLE_API_KEY)
    
    prompt = f"""
Báº¡n lÃ  game designer cho Contexto tiáº¿ng Viá»‡t. HÃ£y liá»‡t kÃª 50-100 tá»« QUAN TRá»ŒNG NHáº¤T mÃ  ngÆ°á»i chÆ¡i sáº½ nghÄ© Ä‘áº¿n khi chÆ¡i game vá»›i tá»« khÃ³a: "{target}".

Chiáº¿n lÆ°á»£c brainstorm theo loáº¡i target:
- Náº¿u lÃ  HOáº T Äá»˜NG/HÃ€NH Äá»˜NG â†’ Æ¯u tiÃªn: cÃ´ng cá»¥/Ä‘á»“ dÃ¹ng chÃ­nh, Ä‘á»‹a Ä‘iá»ƒm thá»±c hiá»‡n, sáº£n pháº©m/káº¿t quáº£
- Náº¿u lÃ  Äá»’ Váº¬T/CÃ”NG Cá»¤ â†’ Æ¯u tiÃªn: bá»™ pháº­n, váº­t liá»‡u, nÆ¡i dÃ¹ng, hÃ nh Ä‘á»™ng liÃªn quan
- Náº¿u lÃ  NGHá»€ NGHIá»†P â†’ Æ¯u tiÃªn: cÃ´ng cá»¥ nghá», nÆ¡i lÃ m viá»‡c, sáº£n pháº©m/dá»‹ch vá»¥
- Náº¿u lÃ  Äá»ŠA ÄIá»‚M â†’ Æ¯u tiÃªn: Ä‘á»“ váº­t Ä‘áº·c trÆ°ng, ngÆ°á»i thÆ°á»ng cÃ³ máº·t, hoáº¡t Ä‘á»™ng chÃ­nh
- Náº¿u lÃ  THá»°C PHáº¨M/áº¨M THá»°C â†’ Æ¯u tiÃªn: nguyÃªn liá»‡u, mÃ³n Äƒn, dá»¥ng cá»¥ cháº¿ biáº¿n

Quy táº¯c Báº®T BUá»˜C:
âŒ KHÃ”NG liá»‡t kÃª tá»« chá»©a target (vÃ­ dá»¥: "ngÆ°á»i {target}", "nghá» {target}", "thá»£ {target}", "Ä‘áº§u {target}")
âŒ KHÃ”NG liá»‡t kÃª tá»« quÃ¡ chung chung khÃ´ng Ä‘áº·c trÆ°ng
âŒ KHÃ”NG liá»‡t kÃª tá»« trá»«u tÆ°á»£ng, khÃ¡i niá»‡m, meta-language

âœ… CHá»ˆ liá»‡t kÃª DANH Tá»ª cá»¥ thá»ƒ, há»¯u hÃ¬nh, Ä‘á»i thÆ°á»ng
âœ… Æ¯u tiÃªn tá»« ngÆ°á»i chÆ¡i phá»• thÃ´ng sáº½ liÃªn tÆ°á»Ÿng NGAY Láº¬P Tá»¨C

VÃ­ dá»¥ minh há»a:
â€¢ "náº¥u Äƒn" â†’ Tá»‘t: gáº¡o, thá»‹t, cÃ¡, muá»‘i, nÆ°á»›c máº¯m, phá»Ÿ, ná»“i, cháº£o, dao, báº¿p
             TrÃ¡nh: quÃ¡n, chá»£, Ä‘áº§u báº¿p, ngÆ°á»i náº¥u, ná»™i trá»£
â€¢ "xe mÃ¡y" â†’ Tá»‘t: xÄƒng, nhá»›t, lá»‘p, phanh, gÆ°Æ¡ng, yÃªn, ga, cÃ²i
             TrÃ¡nh: garage, thá»£ mÃ¡y, bÃ£i xe, ngÆ°á»i lÃ¡i
â€¢ "bÃ¡c sÄ©" â†’ Tá»‘t: bá»‡nh viá»‡n, y tÃ¡, bá»‡nh nhÃ¢n, thuá»‘c, á»‘ng nghe, Ã¡o blouse
             TrÃ¡nh: ngÃ nh y, ngÆ°á»i khÃ¡m, tháº§y thuá»‘c

Tá»« khÃ³a: "{target}"
    """

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config={
                "response_mime_type": "application/json",
                "response_json_schema": BrainstormResponse.model_json_schema(),
            },
        )
        result = BrainstormResponse.model_validate_json(response.text)
        return [w.lower().strip() for w in result.words]
    except Exception as e:
        print(f"   âš ï¸ Lá»—i Brainstorm: {e}")
        raise Exception(f"KhÃ´ng thá»ƒ brainstorm: {e}")

def get_llm_scores(target, words, max_retries=3):
    """Cháº¥m Ä‘iá»ƒm toÃ n bá»™ danh sÃ¡ch tá»« trong 1 láº§n Ä‘á»ƒ Ä‘áº£m báº£o context toÃ n cá»¥c"""
    print(f"   ğŸ¤– [LLM] Äang cháº¥m Ä‘iá»ƒm Gameplay cho: '{target}'...")
    
    client = genai.Client(api_key=GOOGLE_API_KEY)

    prompt = f"""
   Báº¡n lÃ  Game Designer cho trÃ² chÆ¡i Contexto tiáº¿ng Viá»‡t.

    Má»¥c tiÃªu: Xáº¿p háº¡ng cÃ¡c tá»« theo "Äá»™ lÃ³e sÃ¡ng trong nÃ£o" cá»§a ngÆ°á»i chÆ¡i phá»• thÃ´ng khi nghÄ© tá»›i Tá»ª KHÃ“A: "{target}". KhÃ´ng dá»±a theo tá»« Ä‘iá»ƒn hay kiáº¿n thá»©c chuyÃªn ngÃ nh; Æ°u tiÃªn tráº£i nghiá»‡m liÃªn tÆ°á»Ÿng Ä‘á»i thÆ°á»ng.

    Quy táº¯c cháº¥m Ä‘iá»ƒm (0-500), trung láº­p theo chá»§ Ä‘á»:
    - Háº¡ng S (480-500): Äá»“ng nghÄ©a/Ä‘á»“ng nháº¥t; cáº·p gáº¯n bÃ³ khÃ´ng thá»ƒ tÃ¡ch rá»i; váº­t/dá»¥ng/Ä‘á»‹a Ä‘iá»ƒm lÃµi gáº¯n trá»±c tiáº¿p vÃ  thÆ°á»ng xuyÃªn vá»›i target.
    - Háº¡ng A (400-479): Cá»™ng sá»± gáº§n; nÆ¡i chá»‘n Ä‘áº·c trÆ°ng; cÃ´ng cá»¥/bá»™ pháº­n chÃ­nh (náº¿u target lÃ  Ä‘á»“ váº­t); nhá»¯ng danh tá»« cá»¥ thá»ƒ thÆ°á»ng xuáº¥t hiá»‡n cÃ¹ng nhau trong Ä‘á»i sá»‘ng.
    - Háº¡ng B (300-399): HÃ nh Ä‘á»™ng chÃ­nh; tÃ­nh cháº¥t ná»•i báº­t; cÃ´ng cá»¥ phá»¥ trá»£. Äá»™ng tá»« luÃ´n tháº¥p Ä‘iá»ƒm hÆ¡n danh tá»« tÆ°Æ¡ng á»©ng.
    - Háº¡ng C (150-299): LÄ©nh vá»±c lá»›n; khÃ¡i niá»‡m bao trÃ¹m; hypernym chung chung; tá»« liÃªn quan giÃ¡n tiáº¿p.
    - Háº¡ng D (0-149): Pháº¡t máº¡nh cÃ¡c trÆ°á»ng há»£p sau:
        (1) Láº·p target vá»›i tiá»n tá»‘/háº­u tá»‘ rÃ¡c ("ngÆ°á»i {target}", "Ã´ng {target}", "ná»¯ {target}", "cáº£ {target}", "toÃ n {target}").
        (2) Tá»« ghÃ©p chuyÃªn ngÃ nh/chi li quÃ¡ cá»¥ thá»ƒ.
        (3) CÃ¹ng loáº¡i nhÆ°ng khÃ¡c lÄ©nh vá»±c (cross-category).
        (4) Tá»« cá»•/Ã­t dÃ¹ng/HÃ¡n Viá»‡t thuáº§n tÃºy (vÃ­ dá»¥: vÄƒn X, Ä‘áº¡o X, viá»…n X, cá»• X, ngÆ° X...).
        (5) Tá»« meta-ngÃ´n ngá»¯ (cá»¥m tá»«, thuáº­t ngá»¯, tá»« khoÃ¡, khÃ¡i niá»‡m, tÃ­nh cháº¥t, loáº¡i hÃ¬nh, phá»• quÃ¡t...).
        (6) Äá»‹a danh riÃªng láº» náº¿u target khÃ´ng pháº£i Ä‘á»‹a lÃ½ (giáº£m 100-150 Ä‘iá»ƒm).
        (7) Tá»« trÃ¡i nghÄ©a hoáº·c lá»‡ch ngá»¯ cáº£nh.

    NguyÃªn táº¯c báº¯t buá»™c:
    - Chá»‰ cháº¥m cÃ¡c tá»« cÃ³ trong danh sÃ¡ch cung cáº¥p; KHÃ”NG thÃªm hay Ä‘á»•i tá»«.
    - PhÃ¢n hÃ³a Ä‘iá»ƒm: Má»–I Tá»ª NÃŠN CÃ“ ÄIá»‚M KHÃC NHAU. Táº­n dá»¥ng thang Ä‘iá»ƒm rá»™ng 0-500 Ä‘á»ƒ táº¡o khoáº£ng cÃ¡ch há»£p lÃ½ (3-10 Ä‘iá»ƒm).
    - Vá»›i {len(words)} tá»«, hÃ£y phÃ¢n bá»• Ä‘iá»ƒm Ä‘á»u tá»« cao xuá»‘ng tháº¥p, trÃ¡nh dá»“n Ä‘iá»ƒm.
    - Æ¯u tiÃªn danh tá»« cá»¥ thá»ƒ, Ä‘á»i thÆ°á»ng, hiá»‡n Ä‘áº¡i; háº¡n cháº¿ khÃ¡i quÃ¡t/áº©n dá»¥/vÄƒn chÆ°Æ¡ng.
    
    Danh sÃ¡ch tá»« cáº§n cháº¥m Ä‘iá»ƒm:
    {json.dumps(words, ensure_ascii=False)}
    """

    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=prompt,
                config={
                    "response_mime_type": "application/json",
                    "response_json_schema": RankingResponse.model_json_schema(),
                },
            )
            result = RankingResponse.model_validate_json(response.text)
            print(f"   âœ… Cháº¥m Ä‘iá»ƒm thÃ nh cÃ´ng {len(result.items)}/{len(words)} tá»«")
            return result.items
        except Exception as e:
            print(f"   âš ï¸ Lá»—i API (Láº§n {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                raise Exception(f"KhÃ´ng thá»ƒ cháº¥m Ä‘iá»ƒm sau {max_retries} láº§n thá»­: {e}")
            time.sleep(2)
    raise Exception("KhÃ´ng thá»ƒ cháº¥m Ä‘iá»ƒm")

def generate_hints_with_llm(target, rank_map, max_retries=3):
    """
    Táº¡o hints cho game báº±ng LLM, chá»n nhiá»u tá»« Ä‘áº¡i diá»‡n cho tá»«ng khoáº£ng rank.
    
    Args:
        target (str): Tá»« khÃ³a target cá»§a game
        rank_map (dict): Dictionary mapping tá»« -> rank
        max_retries (int): Sá»‘ láº§n thá»­ láº¡i tá»‘i Ä‘a khi gá»i API
    
    Returns:
        list: Array cÃ¡c rank numbers cho hints (vÃ­ dá»¥: [7, 12, 16, 20, 38, ...])
              CÃ³ thá»ƒ chá»©a nhiá»u hints cho má»—i khoáº£ng (2-5 tá»« má»—i khoáº£ng)
              Tráº£ vá» list rá»—ng náº¿u khÃ´ng thá»ƒ táº¡o hints
    
    CÃ¡c khoáº£ng hint Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong HINT_RANGES constant.
    LLM sáº½ cá»‘ gáº¯ng chá»n Ã­t nháº¥t 1 tá»« cho má»—i khoáº£ng.
    """
    print(f"   ğŸ’¡ [LLM] Äang táº¡o hints cho '{target}'...")
    
    # Chá»‰ xá»­ lÃ½ top 2000 tá»«
    sorted_words = sorted(rank_map.items(), key=lambda x: x[1])[:2000]
    
    # Táº¡o danh sÃ¡ch á»©ng viÃªn cho tá»«ng khoáº£ng
    range_candidates = []
    for min_rank, max_rank in HINT_RANGES:
        candidates = [
            {"word": word, "rank": rank}
            for word, rank in sorted_words
            if min_rank <= rank < max_rank and word != target
        ]
        if candidates:
            range_candidates.append({
                "range": f"{min_rank}-{max_rank}",
                "candidates": candidates  # Gá»­i táº¥t cáº£ á»©ng viÃªn cho LLM
            })
    
    if not range_candidates:
        print("   âš ï¸ KhÃ´ng cÃ³ á»©ng viÃªn cho hints")
        return []
    
    client = genai.Client(api_key=GOOGLE_API_KEY)
    
    # Táº¡o prompt cho LLM
    prompt = f"""
Báº¡n lÃ  chuyÃªn gia thiáº¿t káº¿ game Contexto tiáº¿ng Viá»‡t.

Nhiá»‡m vá»¥: Chá»n VÃ€I Tá»ª Ä‘áº¡i diá»‡n tá»‘t nháº¥t cho má»—i khoáº£ng rank dÆ°á»›i Ä‘Ã¢y.
Tá»« khÃ³a target: "{target}"

TiÃªu chÃ­ chá»n tá»« hint:
1. Tá»« PHáº¢I cÃ³ má»©c Ä‘á»™ liÃªn quan rÃµ rÃ ng vá»›i target (khÃ´ng quÃ¡ xa, khÃ´ng quÃ¡ gáº§n)
2. LÃ  danh tá»« cá»¥ thá»ƒ, dá»… hiá»ƒu, phá»• biáº¿n trong Ä‘á»i sá»‘ng
3. GiÃºp ngÆ°á»i chÆ¡i cÃ³ manh má»‘i há»¯u Ã­ch Ä‘á»ƒ suy luáº­n gáº§n hÆ¡n Ä‘áº¿n target
4. TrÃ¡nh cÃ¡c tá»«: quÃ¡ chuyÃªn ngÃ nh, quÃ¡ trá»«u tÆ°á»£ng, hoáº·c chá»©a target trong tá»« ghÃ©p
5. Æ¯u tiÃªn tá»« cÃ³ tÃ­nh cháº¥t gá»£i má»Ÿ, liÃªn tÆ°á»Ÿng tá»± nhiÃªn

Danh sÃ¡ch á»©ng viÃªn theo tá»«ng khoáº£ng:
{json.dumps(range_candidates, ensure_ascii=False, indent=2)}

HÃ£y tráº£ vá» JSON array vá»›i format:
[
  {{"word": "tá»«_1", "rank": sá»‘_rank}},
  {{"word": "tá»«_2", "rank": sá»‘_rank}},
  ...
]

YÃªu cáº§u:
- Chá»n 2-5 tá»« cho má»—i khoáº£ng (tÃ¹y vÃ o sá»‘ lÆ°á»£ng tá»« liÃªn quan cÃ³ trong khoáº£ng)
- Báº®T BUá»˜C Ä‘áº£m báº£o Má»ŒI khoáº£ng Ä‘á»u cÃ³ Ã­t nháº¥t 1 tá»« Ä‘Æ°á»£c tráº£ vá»
- Náº¿u khoáº£ng nÃ o khÃ´ng cÃ³ tá»« liÃªn quan máº¡nh, hÃ£y chá»n tá»« liÃªn quan yáº¿u nháº¥t trong khoáº£ng Ä‘Ã³
- Æ¯u tiÃªn cháº¥t lÆ°á»£ng hÆ¡n sá»‘ lÆ°á»£ng - chá»‰ chá»n cÃ¡c tá»« thá»±c sá»± cÃ³ Ã­ch
"""
    
    for attempt in range(max_retries):
        try:
            response = client.models.generate_content(
                model=MODEL_NAME,
                contents=prompt,
                config={
                    "response_mime_type": "application/json",
                    "response_json_schema": HintResponse.model_json_schema(),
                },
            )
            result = HintResponse.model_validate_json(response.text)
            
            # Chuyá»ƒn Ä‘á»•i thÃ nh array cÃ¡c rank numbers (nhÆ° Ä‘Ã£ lÆ°u trong game files)
            hint_ranks = [item.rank for item in result.hints]
            hint_words = [item.word for item in result.hints]
            
            print(f"   âœ… ÄÃ£ táº¡o {len(hint_ranks)} hints: {hint_ranks}")
            print(f"   ğŸ’¡ Hint words: {hint_words}")
            return hint_ranks
            
        except Exception as e:
            print(f"   âš ï¸ Lá»—i khi táº¡o hints (Láº§n {attempt+1}): {e}")
            if attempt == max_retries - 1:
                raise Exception(f"KhÃ´ng thá»ƒ táº¡o hints sau {max_retries} láº§n thá»­: {e}")
            time.sleep(2)
    
    raise Exception("KhÃ´ng thá»ƒ táº¡o hints")

# =========================== EMBEDDING RANKING ===========================

def run_model_ranking(model_name, model_instance, dictionary, query, k):
    """TÃ­nh ranking cho 1 model"""
    emb_cache = os.path.join(CACHE_DIR, f"{model_name}_vocab_embeddings.npy")

    if os.path.exists(emb_cache):
        corpus_embeddings = np.load(emb_cache)
    else:
        print(f"      Encoding vocab vá»›i {model_name}...")
        corpus_embeddings = model_instance.encode(
            dictionary,
            batch_size=128,
            show_progress_bar=True,
            convert_to_numpy=True,
            normalize_embeddings=True
        )
        np.save(emb_cache, corpus_embeddings)

    # Encode query
    query_embedding = model_instance.encode(
        [query],
        convert_to_numpy=True,
        normalize_embeddings=True
    )

    # FAISS search
    d = corpus_embeddings.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(corpus_embeddings)

    D, I = index.search(query_embedding, min(k, len(dictionary)))

    # Return rank map
    return {dictionary[idx]: rank + 1 for rank, idx in enumerate(I[0])}

def is_valid_candidate(candidate_word, target_word):
    """
    Kiá»ƒm tra tá»« há»£p lá»‡ (PhiÃªn báº£n BÃ³c Vá» HÃ nh - Peeling Loop).
    Logic: BÃ³c háº¿t cÃ¡c lá»›p tá»« rÃ¡c á»Ÿ Ä‘áº§u/cuá»‘i Ä‘i.
    Náº¿u lÃµi cÃ²n láº¡i == target -> LOáº I.
    """

    # 1. Loáº¡i chÃ­nh nÃ³
    if candidate_word == target_word:
        return False

    # 2. Danh sÃ¡ch tá»« rÃ¡c (Token Ä‘Æ¡n)
    NOISE_TOKENS = {
        # LÆ°á»£ng tá»«
        "cÃ¡c", "nhá»¯ng", "má»™t", "má»i", "má»—i", "tá»«ng", "máº¥y", "vÃ i", "bá»n", "nhÃ³m",
        # Loáº¡i tá»«
        "cÃ¡i", "con", "chiáº¿c", "ngÆ°á»i", "nhÃ ", "Ã´ng", "bÃ ", "cÃ´", "chÃº", "anh", "chá»‹", "tháº±ng", "tÃªn", "gÃ£", "viÃªn", "ngÃ i",
        # Danh tá»« trá»«u tÆ°á»£ng hÃ³a (Thá»§ pháº¡m cá»§a 'lá»±c lÆ°á»£ng', 'ngÃ nh', 'há»‡ thá»‘ng')
        "viá»‡c", "sá»±", "cá»¥c", "há»™i", "ngÃ nh", "giá»›i", "ban", "sá»Ÿ", "bá»™",
        "lá»±c", "lÆ°á»£ng", "há»‡", "thá»‘ng", "trÃ¬nh", "Ä‘á»™", "cÃ´ng", "tÃ¡c", "chuyÃªn", "mÃ´n"
    }

    NOISE_SUFFIXES = {"nÃ y", "kia", "Ä‘Ã³", "ná»", "áº¥y", "gÃ¬", "Ä‘Ã¢u", "Æ°", "nhá»‰", "nhÃ©", "háº£", "cá»§a"}

    # 3. TÃ¡ch tá»« Ä‘á»ƒ xá»­ lÃ½
    tokens = candidate_word.split('_')

    # Náº¿u tá»« khÃ´ng chá»©a target thÃ¬ giá»¯ láº¡i
    if target_word not in candidate_word:
        return True

    # --- VÃ’NG Láº¶P BÃ“C TÃCH (PEELING LOOP) ---

    # BÃ³c tá»« Ä‘áº§u (Prefix)
    while len(tokens) > 0 and tokens[0] in NOISE_TOKENS:
        tokens.pop(0)

    # BÃ³c tá»« cuá»‘i (Suffix)
    while len(tokens) > 0 and tokens[-1] in NOISE_SUFFIXES:
        tokens.pop(-1)

    # 4. Kiá»ƒm tra lÃµi cÃ²n láº¡i
    remaining_word = "_".join(tokens)

    # Náº¿u sau khi bÃ³c háº¿t vá» mÃ  lÃµi chÃ­nh lÃ  Target -> RÃC (LOáº I)
    if remaining_word == target_word:
        return False

    # Náº¿u bÃ³c háº¿t sáº¡ch sÃ nh sanh (rá»—ng) -> RÃC (LOáº I)
    if not remaining_word:
        return False

    return True

def generate_rrf_ranking(target, vocab, loaded_models):
    """Táº¡o RRF ranking cho 1 target"""
    print(f"   âš¡ [Embedding] TÃ­nh toÃ¡n RRF cho '{target}'...")

    K_SEARCH = len(vocab)
    rankings_map = {}

    # Cháº¡y táº¥t cáº£ models
    for name in EMBEDDING_MODELS:
        r = run_model_ranking(name, loaded_models[name], vocab, target, k=K_SEARCH)
        rankings_map[name] = r

    # TÃ­nh RRF score
    all_candidates = set()
    for model_rankings in rankings_map.values():
        all_candidates.update(model_rankings.keys())

    print(f"      Tá»•ng {len(all_candidates):,} tá»« tá»« cÃ¡c models")

    final_list = []
    filtered_count = 0
    K_RRF = 60

    for word in all_candidates:
        if not is_valid_candidate(word, target):
            filtered_count += 1
            continue

        # TÃ­nh RRF
        rrf_score = 0
        for model_name, config in EMBEDDING_MODELS.items():
            rank = rankings_map[model_name].get(word, 100000)
            rrf_score += config["weight"] * (1 / (K_RRF + rank))

        final_list.append({"word": word, "rrf_score": rrf_score})

    sorted_words = sorted(final_list, key=lambda x: x["rrf_score"], reverse=True)

    print(f"      â†’ {len(sorted_words):,} tá»« há»£p lá»‡ (filtered {filtered_count:,})")
    return sorted_words

# =========================== FILE PROCESSING ===========================

def process_file(file_path):
    filename = os.path.basename(file_path)
    print(f"\nğŸ”„ Äang xá»­ lÃ½: {filename}")

    # 1. Load file JSON gá»‘c
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    target_word = data.get("keyword")
    rank_map = data.get("rank_map", {})

    if not target_word or not rank_map:
        print(f"   âŒ File lá»—i Ä‘á»‹nh dáº¡ng. Bá» qua.")
        return

    # 2. Chuáº©n bá»‹ dá»¯ liá»‡u
    sorted_items = sorted(rank_map.items(), key=lambda x: x[1])
    embedding_candidates = [item[0] for item in sorted_items[:TOP_K_RERANK]]

    # 3. BRAINSTORMING (Cá»©u há»™ tá»« vá»±ng)
    rescue_words = llm_brainstorm(target_word)
    print(f"   CÃ¡c tá»« Ä‘Æ°á»£c thÃªm: {rescue_words}")

    # Gá»™p danh sÃ¡ch
    combined_candidates = list(set(embedding_candidates + rescue_words))

    # 4. Gá»ŒI GEMINI RE-RANK (toÃ n bá»™ danh sÃ¡ch Ä‘á»ƒ giá»¯ context)
    print(f"   ğŸ¤– Gá»­i {len(combined_candidates)} tá»« cho Gemini...")
    llm_results = get_llm_scores(target_word, combined_candidates)

    # 5. Há»£p nháº¥t káº¿t quáº£ (Merge)
    final_rank_map = {}
    current_rank = 1

    # LuÃ´n giá»¯ Target á»Ÿ Rank 1
    final_rank_map[target_word] = current_rank
    current_rank += 1

    # A. Xá»­ lÃ½ pháº§n Ä‘áº§u (LLM)
    processed_words_set = set()
    # Chá»‰ cháº¥p nháº­n tá»« do LLM tráº£ vá» náº¿u náº±m trong danh sÃ¡ch á»©ng viÃªn
    combined_set = set(combined_candidates)

    if llm_results:
        sorted_llm = sorted(llm_results, key=lambda x: x.s, reverse=True)

        for item in sorted_llm:
            if item.w == target_word:
                continue
            # Bá» qua tá»« khÃ´ng náº±m trong danh sÃ¡ch á»©ng viÃªn Ä‘á»ƒ trÃ¡nh LLM bá»‹a thÃªm
            if item.w not in combined_set:
                continue
            # Bá» qua tá»« Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ (trÃ¡nh duplicate)
            if item.w in processed_words_set or item.w in final_rank_map:
                continue
            final_rank_map[item.w] = current_rank
            processed_words_set.add(item.w)
            current_rank += 1
    else:
        print("   âš ï¸ LLM Re-rank tháº¥t báº¡i. Sáº½ dÃ¹ng thá»© tá»± gá»‘c.")

    # B. Xá»­ lÃ½ pháº§n Ä‘uÃ´i (Embedding + Fallback)
    for w, old_rank in sorted_items:
        if w == target_word:
            continue
        # Bá» qua tá»« Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ (trÃ¡nh duplicate)
        if w in final_rank_map or w in processed_words_set:
            continue
        final_rank_map[w] = current_rank
        current_rank += 1

    # 6. Táº¡o hints vá»›i LLM
    hints = generate_hints_with_llm(target_word, final_rank_map)
    
    # 7. Xuáº¥t file káº¿t quáº£
    output_path = os.path.join(OUTPUT_FOLDER, filename)
    output_data = {
        "keyword": target_word,
        "rank_map": final_rank_map
    }
    
    # ThÃªm hints vÃ o output náº¿u cÃ³
    if hints:
        output_data["hints"] = hints

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    if hints:
        print(f"   âœ… ÄÃ£ lÆ°u: {output_path} (Tá»•ng: {len(final_rank_map)} tá»«, {len(hints)} hints)")
    else:
        print(f"   âœ… ÄÃ£ lÆ°u: {output_path} (Tá»•ng: {len(final_rank_map)} tá»«, no hints generated)")
    print(f"   ğŸ† Top 50 Má»›i: {list(final_rank_map.keys())[:50]}")
    
    return output_path

def save_to_contexto_and_update_loader(output_file, target_word):
    """
    Sao chÃ©p file output vÃ o lib/contexto vÃ  cháº¡y create_rank_loader.py
    """
    print("\nğŸ“¦ Äang lÆ°u vÃ o lib/contexto...")
    
    # Táº¡o slug tá»« target_word (bÃ¡c sÄ© -> bac_si)
    slug = remove_vietnamese_accents(target_word.replace(" ", "_"))
    
    # ÄÆ°á»ng dáº«n Ä‘Ã­ch
    dest_file = CONTEXTO_DIR / f"{slug}.json"
    
    # Sao chÃ©p file
    import shutil
    try:
        shutil.copy2(output_file, dest_file)
        print(f"   âœ… ÄÃ£ lÆ°u: {dest_file}")
    except Exception as e:
        print(f"   âŒ Lá»—i khi sao chÃ©p file: {e}")
        return False
    
    # Cháº¡y create_rank_loader.py
    print("\nğŸ”„ Äang cáº­p nháº­t rankLoader.json...")
    create_rank_loader_script = CONTEXTO_DIR / "create_rank_loader.py"
    
    if not create_rank_loader_script.exists():
        print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y {create_rank_loader_script}")
        return False
    
    try:
        result = subprocess.run(
            ["python3", str(create_rank_loader_script)],
            cwd=str(CONTEXTO_DIR),
            capture_output=True,
            text=True,
            check=True
        )
        print(result.stdout)
        print("   âœ… ÄÃ£ cáº­p nháº­t rankLoader.json")
        return True
    except subprocess.CalledProcessError as e:
        print(f"   âŒ Lá»—i khi cháº¡y create_rank_loader.py: {e}")
        print(f"   Output: {e.stdout}")
        print(f"   Error: {e.stderr}")
        return False

# =========================== MAIN ===========================

def main():
    print("="*70)
    print("ğŸš€ CONTEXTO DAILY RANKING PIPELINE")
    print("="*70)
    
    # Generate daily target
    target_word = generate_daily_target()
    target_word_underscore = target_word.replace(" ", "_")
    
    # Load vocab
    vocab = load_vocab()
    print(f"ğŸ“¥ Loaded {len(vocab):,} words from vocab\n")

    # Pre-load models
    print("ğŸ“¦ Pre-loading embedding models...")
    loaded_models = {}
    for name, config in EMBEDDING_MODELS.items():
        print(f"   - Loading {name}...")
        loaded_models[name] = SentenceTransformer(config["path"])
    print("âœ… All models loaded\n")

    print("="*70)
    print(f"TARGET: '{target_word.upper()}'")
    print("="*70)

    start_time = time.time()

    try:
        # Táº¡o RRF ranking
        rrf_ranking = generate_rrf_ranking(target_word_underscore, vocab, loaded_models)

        # Táº¡o rank_map
        rank_map = {}
        rank_map[target_word] = 1

        for rank, item in enumerate(rrf_ranking, start=2):
            rank_map[item['word'].replace("_", " ")] = rank

        # LÆ°u file JSON
        output_data = {
            "keyword": target_word,
            "rank_map": rank_map
        }

        intermediate_file = f"{INPUT_FOLDER}/{remove_vietnamese_accents(target_word_underscore)}.json"
        with open(intermediate_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, separators=(',', ':'))

        elapsed = time.time() - start_time
        file_size = os.path.getsize(intermediate_file) / 1024

        print(f"   âœ… Saved RRF: {intermediate_file} ({file_size:.1f} KB, {len(rank_map)} words)")
        print(f"   ğŸ† Top 50: {list(rank_map.keys())[:51]}")
        print(f"   â±ï¸  Completed in {elapsed:.1f}s\n")

        # Re-rank phase
        print("\nğŸ¯ Starting LLM Re-rank phase...")
        final_output = process_file(intermediate_file)

        # LÆ°u vÃ o lib/contexto vÃ  cáº­p nháº­t rankLoader
        if final_output:
            success = save_to_contexto_and_update_loader(final_output, target_word)
            if success:
                print("\nğŸ‰ HOÃ€N Táº¤T! File Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o lib/contexto vÃ  rankLoader Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t.")
            else:
                print("\nâš ï¸  HOÃ€N Táº¤T nhÆ°ng cÃ³ lá»—i khi cáº­p nháº­t contexto/rankLoader.")
        else:
            print("\nğŸ‰ HOÃ€N Táº¤T!")

    except Exception as e:
        print(f"   âŒ Error: {e}\n")
        raise

if __name__ == "__main__":
    # Force unbuffered output (alternative method)
    import functools
    print = functools.partial(print, flush=True)
    
    main()
